\chapter{Limitations}
\label{chap:limitations}

We now discuss limitations of the systems presented in this dissertation. We
begin with limitations that are common to all three systems. We then discuss
limitations of each individual system.

\section{Limitations common to all three systems}

\subsection{Lack of silicon implementations} None of our three systems has a
hardware implementation in silicon. This is a problem that arises whenever a
new system requiring hardware modifications needs to be evaluated. Designing a
new chip can take a few years, and it requires both a significant financial
investment and access to a large team of engineers.

 As a result, we evaluated the three systems in this dissertation using a
combination of simulation to check correctness and synthesis experiments to
evaluate area overheads of new hardware designs. We briefly considered an FPGA
implementation on the NetFPGA platform~\cite{netfpga}, but decided against it
because the relative areas consumed by router subsystems on an FPGA may not
accurately reflect the relative area consumptions on a router chip.

Instead, we paid careful attention to keeping our hardware designs simple, and
reused standard hardware designs (\eg LRU caches and First In First Out Queues)
wherever possible. To allow a router chip designer to leverage our results, we
clearly specified the interfaces between the different hardware blocks in our
design.

There is still value to an FPGA implementation, which we hope to explore in
future work. First, an FPGA implementation allows us to check the correctness
of the same Verilog code that we use for synthesis experiments, especially to
test correctness when interfacing a router with the external world. Second, an
FPGA implementation can serve as a vehicle for end-to-end evaluation of ideas,
much like our Mininet evaluation (\S\ref{sec:eval:mininet}).
Third, the development of new FPGA technology that allows clock rates of up to
1 GHz~\cite{hyperflex} suggests a way to prototype hardware at near-ASIC speeds
while benefiting from the reconfigurability of an FPGA. Note that, even with
such high speed FPGAs, an ASIC design of the hardware would still be required
for large-scale commercial production of the hardware design.  This is because,
relative to an ASIC, an FPGA consumes more power, occupies more chip area,
and has a higher unit price.

\subsection{Lack of completeness theorems}
\label{ss:limit_completeness}

We do not have a formal characterization of what can and cannot be done by each
system. While we have examples of algorithms that cannot be expressed by each
system, it would be ideal to have a ``completeness'' theorem that states that
all algorithms within a class (and within that class alone) can be expressed
using a particular system. Such theorems would also give a formal assurance of
a system being ``future proof'' so long as a new algorithm falls within a
particular class of algorithms. An example of such a theorem is the equivalence
of finite-state machines and regular expressions, which states that any regular
expression---whether a regular expression that is known today or a regular
expression that shows up in the future---can be expressed using a finite-state
machine.

\subsection{Lack of a user study} One way to empirically study the ``future
proofness'' of a programming abstraction is to freeze the abstraction and then
run a user study with new programmers who have never seen the abstraction
before. We have not been able to carry out a such a user study because the
concept of programming the data plane of a high speed network is relatively new
and has not seen widespread adoption yet.

At the same time, some of our results suggest that our abstractions and
primitives may be general. For instance, as mentioned earlier, the atoms
developed in Domino (Chapter~\ref{chap:domino}) supported unanticipated use
cases that were developed after the atom designs were frozen
(Table~\ref{tab:atoms_generalize}). Similarly, we did not anticipate the
rate-controlled service disciplines (RCSD) as a use case for PIFOs when first
designing PIFOs, but later found that PIFOs could express the RCSD class
(\S\ref{s:expressive}).  Finally, the atomic semantics of  packet transactions
are now part of the P4 language (\S\ref{s:impact}), suggesting that the
packet transaction abstraction might be quite general and natural.

\subsection{Supporting routers with multiple pipelines}
\label{ss:multiple_pipelines}

As discussed earlier (\S\ref{s:absmachine}), throughout this dissertation, we
assume a router architecture with a single ingress pipeline and a single egress
pipeline shared across all ports. These pipelines can be made to run at a clock
rate of up to 1 GHz, which at the minimum packet size of 64 bytes, translates
into an aggregate capacity of \textasciitilde640 Gbit/s, after accounting for
minimum inter-packet gaps~\cite{rmt}.

To scale beyond this aggregate capacity, a router needs multiple parallel
pipelines, each devoted to a subset of the router's ports. This has
implications for all our designs, which we discuss below.

\Para{Domino.} In Domino, state is local to an atom, and hence to the pipeline
stage containing that atom.  In a single pipeline router, a pipeline stage can
see all the packets arriving at the router. This allows the pipeline stage to
maintain and update the state consistently, \eg a counter that counts the
number of bytes received across all ports.

In a multi-pipeline router, no single pipeline sees all packets, so the state
in a pipeline stage can only be updated by packets belonging to ports assigned
to that pipeline. This may suffice for some applications, \eg per-port state
that is maintained in each pipeline, which does not need to be accessed from
other pipelines. 

For simple stateful operations like global, router-wide, counters, the
associativity of addition allows us to update the state separately in each
pipeline and combine it through addition later. However, we know of no general
mechanism to combine pipeline-local state into a single, global, router-wide state value
in a manner that emulates a single-pipeline router. Using a single state value
that is accessed by multiple pipelines is a potential solution, but sharing
state requires multi-ported memory and locking. Multi-ported memory is
expensive, while locking degrades performance.

\Para{Performance queries.} Because the {\ct groupby} operator in \TheSystem
maintains and update state in the data plane, performance queries share the
same limitations as Domino when it comes to multi-pipeline routers. The reason
is the same: multi-pipeline routers have a separate instance of state for every
pipeline that needs to be efficiently combined into a global router-wide state
value without losing accuracy.

\Para{PIFOs.} A multi-pipeline router has multiple ingress and egress pipelines
that share access to the scheduler subsystem alone. The scheduler subsystem is
common to all pipelines and consists of the data buffer to store packet
payloads and the scheduling logic for different scheduling algorithms. To
support enqueues and dequeues from multiple pipelines into the data buffer
every clock cycle, the data buffer memory in a multi-pipeline router is
multi-ported to support multiple writes/reads from multiple ingress/egress
pipelines every clock cycle.

In multi-pipeline routers, each PIFO block needs to support multiple enqueue
and dequeue operations per clock cycle (as many as the number of ingress and
egress pipelines). This is because packets can be enqueued from any of the
input ports every clock cycle, and each input port could reside in any of the
ingress pipelines. Similarly, each egress pipeline requires a new packet every
clock cycle, resulting in multiple dequeues every clock cycle.

We leave a full fledged PIFO design for multi-pipeline routers to future work,
but observe that our current PIFO design facilitates a multi-pipeline
implementation.  A rank store supporting multiple pipelines is similar to the
data buffers of multi-pipeline routers today, which already support multiple
enqueues and dequeues. Building a flow scheduler to support multiple
enqueues/dequeues per clock cycle is relatively easy because the flow scheduler
is maintained in flip flops. A flip-flop-based implementation makes it simpler
to add multiple ports, relative to an implementation using SRAM.

\section{Domino limitations}
\label{sec:domino_limitations}
The \pktlanguage compiler doesn't aggressively optimize, instead focusing on
generating sub-optimal, but correct, pipeline configurations. For instance, it
is possible to fuse two stateful codelets incrementing two independent counters
into the same instance of the Pairs atom. However, by carrying out a one-to-one
mapping from codelets to the atoms implementing them, our compiler precludes
these optimizations. One practical implication of this is that we have had to
manually rewrite programs to make them compile
(Table~\ref{tab:atoms_generalize}), instead of a compiler rewriting such
programs automatically.

Supporting multiple packet transactions in \pktlanguage also requires further
work. This is especially important because any real program running on a router
is likely to execute multiple transactions, each on a subset of the packets
seen by the router. When a router executes multiple transactions, there may be
opportunities for inter-procedural analysis~\cite{dragonbook}, which goes
beyond compiling individual transactions and looks at multiple transactions
together.  For instance, the compiler could detect computations common to
multiple transactions and execute them only once.

\section{PIFO limitations}
\label{sec:pifo_limitations}

Our programming model for scheduling based on PIFOs is a scheduling tree with
scheduling and shaping transactions. While a scheduling tree makes it possible
to program new scheduling algorithms using PIFOs, it does not make it easy. We
have found that it requires considerable effort to program new scheduling
algorithms using scheduling trees.  In other words, scheduling trees are still
a low-level abstraction. We need to raise the level of abstraction if we hope
to make programmable scheduling more broadly accessible to network operators.

Our current PIFO design scales to 2048 flows. If these 2048 flows are allocated
evenly across 64 ports in a 64-port 10G router, we could program scheduling
across 32 flows at each port. This permits per-port scheduling across traffic
aggregates (\eg fair queueing across 32 VMs/tenants within a server), but not
at a finer granularity (\eg 5-tuples). Ideally, to schedule at the finest
granularity, our flow scheduler would realize the ideal PIFO where each packet
in the PIFO belongs to a different flow. We currently support only 2048 flows,
while we can support up to 60K packets.  More design work is required to close
this gap between the number of flows and the number of packets and realize an
idealized PIFO.

\section{Marple limitations}
\label{sec:pq_limitations}

The most important limitation of performance queries is the fact that the
latest value of the aggregated state is not available in the data plane, and is
only accessible to software reading the backing store. This manifests itself
most when using the {\ct emit()} statement in our programs, which requires
access to the latest value of the aggregated state in the data plane.
Currently, we handle such queries by not evicting entries from a key-value
store if the state stored in those entries is emitted to another query
downstream. But not evicting keys severely limits the scalability of the
key-value store because all keys must fit within the small on-chip cache.
Unfortunately, this is unavoidable if we want access to the latest value of
state during {\ct emit()}s.

A similar scalability limitation affects queries that are not linear-in-state
because there is no way to evict key-value pairs while still guaranteeing
correctness if the query is not linear-in-state. In practice, we have found
(\S\ref{sec:workaround-nonscalable}) that it is possible to rewrite measurement
functionality in such a way that the resulting query is linear-in-state, at
some cost to measurement fidelity.
