\chapter{Limitations}
\label{chap:limitations}

One major limitation shared by all three systems is that we do not have silicon
implementations of any of them. Instead, we evaluated these systems using a
combination of simulation and microbenchmarks. We briefly considered an FPGA
implementation on the NetFPGA platform~\cite{netfpga}, but decided against it
because the relative areas consumed by router subsystems on an FPGA do not
accurately reflect the relative area consumptions on a router ASIC.  That said,
we paid careful attention to keeping the hardware designs simple, clearly
articulated the interfaces between the different hardware blocks, and evaluated
the area consumed by our hardware designs by synthesizing them to a recent
transistor library. We hope that the results here make a strong case for router
chip manufacturers to design router chips that support the systems in this
dissertation. We now discuss limitations of each of the three projects.

\section{Domino}
\label{sec:domino_limitations}
The \pktlanguage compiler doesn't aggressively optimize, instead focusing on
generating sub-optimal, but correct pipeline configuration. For instance, it is
possible to fuse two stateful codelets incrementing two independent counters
into the same instance of the Pairs atom. However, by carrying out a one-to-one
mapping from codelets to the atoms implementing them, our compiler precludes
these optimizations.  Developing an {\em optimizing} compiler for packet
transactions is an area for future work.

Supporting multiple packet transactions in \pktlanguage also requires further
work, especially because any real program running on a router is likely to
execute multiple transaction, each on a subset of the packets seen by the
router. When a router executes multiple transactions, there may be
opportunities for inter-procedural analysis~\cite{dragonbook}, which goes
beyond compiling individual transactions and looks at multiple transactions
together.  For instance, the compiler could detect computations common to
multiple transactions and execute them only once.

Finally, we have a manual and ad hoc design process for atoms. Currently, we
use a process of trial and error to first guess atoms and then use our compiler
to check if those atoms can support useful algorithms.  Formalizing this design
process and automating it into an atom-design tool would be useful when
designing router instruction sets. For instance, given a corpus of data-plane
algorithms, this tool would automatically mine the corpus for recurring motifs
of state and packet header modification. A router hardware engineer could then
design hardware for atoms that capture these motifs.

\section{PIFOs}
\label{sec:pifo_limitations}

Our programming model for scheduling based on PIFOs is a scheduling tree with
scheduling and shaping transactions. While the scheduling tree makes it
\textit{possible} to program new scheduling algorithms using PIFOs, it does not
make it \textit{easy}. We have found that it requires considerable effort to
program new scheduling algorithms using scheduling trees.  In other words,
scheduling trees are still a low-level abstraction. We need to raise the level
of abstraction if we hope to make programmable scheduling more broadly
accessible to network operators.

Beyond a few counter examples, we lack a formal characterization of the
scheduling algorithms that cannot be implemented using PIFOs. For instance, is
there a simple, checkable property separating algorithms that can and cannot be
implemented using PIFOs? Given an algorithm specification, can we automatically
check if the algorithm can be programmed using PIFOs?

Our current PIFO design scales to 2048 flows. If these 2048 flows are allocated
evenly across 64 ports in a 64 port 10G router, we could program scheduling
across 32 flows at each port. This permits per-port scheduling across traffic
aggregates (\eg fair queueing across 32 VMs/tenants within a server), but not
a finer granularity (\eg 5-tuples). Ideally, to schedule at the finest
granularity, our flow scheduler would realize the ideal PIFO where each packet
in the PIFO belongs to a different flow. We currently support only 2048 flows,
while we can support up to 60K packets.  More design work is required to close
this gap between the number of flows and the number of packets and realize an
idealized PIFO.

%TODO: Do something about the stuff at the top of pifo_discussion.tex. It's not used anywhere right now.

\section{Performance queries}
\label{sec:pq_limitations}

The major limitation of performance queries is that the latest value of the
aggregated state is not available in the data plane, and is only accessible to
software reading the backing store. This manifests itself most when using the
emit keyword in our programs, which requires access to the latest value of the
aggregated state in the data plane. Currently, we handle such queries by not
evicting those entries from a key-value store if the state stored in those
entries is emitted to another query downstream. But not evicting keys severely
limits the scalability of the key-value store because all keys must fit within
the small on-chip cache. This is unavoidable if we want access to the latest
value of state during emits.

A similar scalability limitation affects queries that are not linear-in-state
because there is no way to evict key-value pairs while still guaranteeing
correctness if the query is not linear-in-state. In practice, we have found
that it is possible to rewrite measurement functionality in such a way that the
resulting query is linear-in-state.
