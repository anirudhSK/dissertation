\newcommenter{an}{1.0,0.0,0.0}
% An abridged history of programmability in routers and how it relates to this dissertation

% The early days of routers: 1969 through the mid 90s
% Everything was in software

% Active Networks: mid to late 90s
% Execute programs carried by packets

% Software routers and NPUs: 99 to present: Click (99), IXPs (2001), RouteBricks, PacketShader, NetFPGA, etc., and associated languages for software routers (packetC, Intel's C dialects, etc.).
% Turn a CPU/GPU/FPGA/multi-core into a router

% Software-defined networking (2008 to now): SANE, Ethane, OpenFlow, and associated languages (Pyretic, Frenetic, etc.). Could incorporate OpenSketch, FAST, DevoFlow, etc. here
% Unified interface to high-speed switching chips
% Promise: this unified interface will solve all our programmability problems

% One possibility for SDNv2.0: Fabric-based SDN (HotSDN 2013), edge-core split
% Too much feature creep in OpenFlow; propose that routers just do source routing, edge does rest

% Another possibility for SDNv2.0: Programmable switching chips (2013): XPliant, FlexPipe, Tofino, RMT, Gibbs parsing paper
% Actually make routers programmable, but restricted to match-action processing and parsing

% Concurrent work (since 2013): FastPass/Flexplane, TPP, INT, SNAP, UPS, UnivMon, SONATA etc.

\chapter{Background and Related Work}
\label{chap:related}

We now survey related work beginning with work that is related to the broader
goals of this dissertation, and then focus on work that is related to specific
chapters.

\Para{Programmable and fast routers.}
Recent academic work~\cite{rmt} and commercial router chips~\cite{tofino,
flexpipe, xpliant} have considered the problem of building routers that are
both fast and programmable. The P4 programming language~\cite{p4} has emerged
as an industry effort towards a standard programming language for these chips.
To the extent that we can glean from publicly available documents, these chips
provide flexibility on only two counts: recognizing user-specific header
formats and programmatically manipulating packet headers for functions such as
forwarding, tunneling, and access control. In particular, they do not provide
the programmability required to implement the grayed-out algorithms in
Figure~\ref{fig:router_evolution}.  These algorithms require the ability to
programmatically manipulate router state on every packet, the ability to
program which packet a router link must transmit next, and the ability to
program what statistics a router must measure. We hope this
dissertation suggests directions in which programmable router
 chips could evolve in the future.

\Para{Abstract machines for line-rate routers.}
The closest work related to the \absmachine machine model is
NetASM~\cite{netasm}. NetASM is an abstract machine and intermediate
representation (IR) for programmable data planes that is portable across
network devices: FPGAs, virtual routers, and line-rate routers.  \absmachine
is a low-level machine model for line-rate routers alone and can be used as a
NetASM target. Because of its role as a low-level machine model, \absmachine
models practical constraints required for line-rate operation
(\S\ref{s:atomConstraints}) that an IR like NetASM does not have to. For
instance, \absmachine machines do not permit sharing state between atoms and use
atom templates to limit computations that can happen at the router's line rate.

\Para{End-host-centric programmability.}
Eden~\cite{eden} provides a programmable data plane using commodity routers by
programming end hosts alone. \pktlanguage targets programmable routers that
provide more flexibility relative to an end-host-only solution. For instance,
\pktlanguage allows us to program in-network congestion control and AQM
schemes, which are beyond Eden's capabilities.  Tiny Packet Programs
(TPP)~\cite{tpp} allow end hosts to embed small programs in packet headers,
which are then executed by the router. TPPs use a restricted instruction set to
facilitate router execution; we show that router instructions must and can be
substantially richer (Table~\ref{tab:templates}).
%for stateful data-plane
%algorithms.
%%
%%Software routers~\cite{routebricks, click} and network processors~\cite{ixp4xx}
%%are flexible, but at least 10$\times$--100$\times$ slower than programmable
%%routers~\cite{xpliant, tofino}.  FPGA-based platforms like the Corsa DP
%%6440~\cite{corsa}, which supports an aggregate capacity of 640 Gbit/s, are
%%faster, but still 5$\times$--10$\times$ slower than programmable
%%routers~\cite{tofino, xpliant}.

\Para{Programming languages for networks.} Many programming languages target
the network control plane~\cite{frenetic, maple}. \pktlanguage focuses on the
data plane. Several DSLs target the data plane. Click~\cite{click} uses C++ for
packet processing on software routers. packetC~\cite{packetc}, Intel's
auto-partitioning C compiler~\cite{intel_uiuc_pldi}, and Microengine
C~\cite{microenginec} target network processors. \pktlanguage's C-like syntax
and sequential semantics are inspired by these DSLs. However, because it
targets line-rate routers, \pktlanguage is more constrained. For instance,
because compiled programs run at line rate, \pktlanguage forbids loops, and
because \absmachine has no shared state, \pktlanguage has no synchronization
constructs.

% TODO: Not sure if the below paragraph should be here.
\Para{Compiling to programmable routers.}
Jose et al.~\cite{lavanya_compiler} focus on compiling P4 programs to
programmable data planes such as the RMT and FlexPipe~\cite{flexpipe} architectures. Their work
focuses only on compiling stateless data-plane tasks such as forwarding and
routing, while the \pktlanguage compiler handles stateful data-plane
algorithms.

\Para{Stateful packet-processing abstractions.}
SNAP~\cite{snap} programs stateful data-plane algorithms using a network
transaction: an atomic block of code that treats the entire network as one
router~\cite{onebigswitch}. It then uses a compiler to translate network
transactions into rules on each router. SNAP needs a compiler to compile these
router-local rules to a router's pipeline, and can use \pktlanguage for this
purpose. FAST~\cite{fast} provides router support and software abstractions for
state machines. \absmachine's atoms support more general stateful processing
beyond state machines that enable a much wider class of data-plane algorithms.

\Para{The Push-in First-out Queue.}
\an{PIFOs were first introduced as a proof construct to prove that a
combined input-output queued router could exactly emulate an output-queued
router~\cite{pifo}. We show here that PIFOs can be used as an abstraction for
programmable scheduling at line rate.}

%TODO
%%\Para{Packet scheduling algorithms.}
%%The literature is replete with scheduling algorithms~\cite{pFabric, hpfq,
%%stopngo, stfq, lstf, srpt, drr, rcsd} . Yet, line-rate routers support only a
%%few: DRR, traffic shaping, and strict priorities. As \S\ref{s:expressive}
%%shows, PIFOs allow a line-rate router to run many of these scheduling
%%algorithms, which, so far, have only been run on software routers.

\Para{Universal Packet Scheduling (UPS).} UPS~\cite{ups} shares our goal of
flexible packet scheduling by seeking a single scheduling algorithm that is
{\em universal} and can emulate any scheduling algorithm. Theoretically, UPS
finds that the well-known LSTF scheduling discipline~\cite{lstf} is universal
if packet departure times for the scheduling algorithm to be emulated are known
up front. Practically, UPS shows that by appropriately initializing slacks, many different scheduling objectives can be
emulated using LSTF. LSTF is programmable using PIFOs, but the set of schemes
practically expressible with LSTF is limited. For example, LSTF cannot
express:
\begin{CompactEnumerate}
\item Hierarchical scheduling algorithms such as HPFQ, because it
  uses only one priority queue.
\item Non-work-conserving algorithms. For such algorithms LSTF must know the
  departure time of each packet up-front, which is not practical.
\item Short-term bandwidth fairness in fair queueing, because LSTF maintains no
  router state except one priority queue. As shown in
  Figure~\ref{fig:sched_trans}, programming a fair queueing algorithm requires us
  to maintain a virtual time state variable. Without this, a new flow could have
  arbitrary virtual start times, and be deprived of its fair share indefinitely.
  UPS provides a fix to this that requires
  estimating fair shares periodically, which is hard to do in
  practice.
  %TODO: Check that this point is accurate.
\item Scheduling policies that aggregate flows from distinct endpoints into a
  single flow at the router. An example is fair queueing across video and web
  traffic classes, regardless of endpoint.  Such policies require the router to
  maintain the state required for fair queueing because no end point sees all the
  traffic within a class.  However, LSTF cannot maintain and update router state
  progammatically.
\end{CompactEnumerate}
\an{The restrictions in UPS/LSTF are a result of a limited programming
model. UPS assumes that routers are fixed and cannot be programmed to modify
packet fields. Further, it only has a single priority queue.  By using atom
pipelines to execute scheduling and shaping transactions, and by composing
multiple PIFOs together, PIFOs express a wider class of scheduling algorithms.}

%\begin{figure}
%  \centering
%  \includegraphics[width=0.7\columnwidth]{state_reqd.pdf}
%  \caption{A router's scheduling algorithm, such as WFQ, might aggregate flows
%  from different end hosts into a single flow at the router for the purpose of
%  scheduling.}
%  \label{fig:state}
%\end{figure}

\Para{Hardware designs for priority queues.}
\an{P-heap is a pipelined binary heap scaling to 4-billion entries~\cite{bhagwan,
pheap}.  However, each P-heap supports traffic belonging to a {\em single} 10
Gbit/s input port in an input-queued router; there is a separate P-heap
instance for each port~\cite{bhagwan}.  Having a separate P-heap per port incurs prohibitive
area overhead on a shared-memory router, and prevents sharing of the data
buffer and binary heap across output ports. Conversely, it is not easy to
overlay multiple logical PIFOs over a single P-heap, which would allow the
P-heap to be shared across ports.}
%%
%%\an{
%%In contrast to a hardware implementation of a generic priority queue as a heap,
%%our design for the PIFO exploits two domain-specific insights. First, there is
%%considerable structure in the ranks: ranks within a flow strictly increase with
%%time.  Second, the packet buffers on shared-memory routers used in datacenters
%%today are much smaller than those on deep-buffered core routers in the past.
%%This permits a simpler, albeit less scalable, design relative to heaps.
%%}

\Para{Endpoint-based monitoring.} Owing to limited router support for
measurement, many systems monitor network performance from endpoints
alone~\cite{netpoirot, minlan-snap, dapper-sosr, trumpet, azure-smartnic}.
While endpoint solutions are necessary for application context (\eg socket
calls), they are inadequate to debug all network problems. A real network needs
both endpoint and router-based systems because each sees something the other
cannot.

\Para{Router-based monitoring.} Traditionally, router-based monitoring has
focused on per-flow counts, not performance measurement. For example,
NetFlow~\cite{netflow} and sFlow~\cite{sflow} provide traffic summaries
through flow and packet sampling. Packet-capture systems~\cite{cisco-span,
niksun, netsight, everflow, pathdump, path_query} collect entire packets or
digests. These approaches sample extensively to lower collection
overheads, and are useful for posthoc traffic analysis. However, neither
approach captures details of {\em performance} phenomena (\eg TCP incast) as
specified by a flexible language like \TheSystem.

\Para{Sketches.} Sketches~\cite{univmon, flowradar, counterbraids, dream} and
earlier work on programmable router measurements~\cite{progme, opensketch}
provide traffic volume statistics using summary data structures on routers.
Unlike sketches, \TheSystem does not have an accuracy-memory tradeoff, since
counting is linear-in-state and counters can be scalably implemented in \TheSystem. Instead,
\TheSystem trades off memory size with cache eviction rate (\Sec{eval}).
\TheSystem also allows users to perform a broader set of aggregations with full
accuracy.

%% \TheSystem also enables users
%% to perform other more general aggregations without losing accuracy.

%
%With INT alone, performance information may be lost, since packets carrying the
%INT data may be dropped on the way to endpoints.

\Para{Recent router support for measurement.}
In-band Network Telemetry (INT)~\cite{int, tpp} exposes queue lengths to
endpoints by stamping it on the packet itself. \TheSystem builds on INT and
provides flexible filters and aggregations {\em directly in routers}.
\TheSystem's data aggregation in routers saves the bandwidth needed to collect
INT data distributed over many endpoints.  In addition, the Tetration chip
provides flow-level telemetry, exposing a fixed set of metrics including
latency, window and packet size variation, and a ``burst
measurement''~\cite{tetration-telemetry}. In contrast, \TheSystem provides
programmable aggregation functions and flow definitions, \eg input/output port versus 5-tuple.

\Para{Network query languages.} Prior network query languages~\cite{gigascope,
frenetic, path_query, streaming-monitoring} allow users to ask questions
primarily about traffic volumes, since their input data is
collected using NetFlow and match-action rule counters~\cite{openflow}. In
contrast, \TheSystem enables expressive {\em performance} questions on
data collected with purpose-built router hardware. \TheSystem shares some
language constructs with Gigascope~\cite{gigascope} and
Sonata~\cite{streaming-monitoring}, but supports aggregations directly in the
router.
%functional and relational constructs

\Para{Language-directed computer design.} Language-directed hardware design (Chapter~\ref{chap:perf_query})
is inspired by language-directed computer design~\cite{language-directed-computer-design,
ditzel_patterson, soar}, aimed at designing efficient hardware to support
expressive high-level languages.
