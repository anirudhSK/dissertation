\newcommenter{an}{1.0,0.0,0.0}
\chapter{Related Work}
\label{chap:related}

This chapter provides a chronological overview of related work on programamble
networks, with an emphasis on how past work relates to this dissertation.

\section{Early routers (1969 to the mid 90s)}
The earliest documented router on a packet-switched network is the Interface
Message Processor (IMP) on the ARPANET in 1969~\cite{imp}. The IMP described in
the original IMP paper~\cite{imp} was implemented on the Honeywell DDP-516
minicomputer. In today's terminology, such a router would be called a software
router because it was implemented as software on top of a general-purpose
Turing-complete computer.

This approach of implementing routers on top of minicomputers was sufficient
for the modest forwarding rates required at the time. For instance, the IMP
paper reports that the maximum throughput of the IMP was around 700 Kbit/s.
Implementing routers on top of minicomputers was also eminently programmable:
changing the functionality of the router simply required upgrading the
forwarding software and loading the minicomputer with a new piece of software.

This software router approach to building routers continued into the mid 90s.
Notable examples of software routers during the 1970s were David Mills'
Fuzzball router~\cite{fuzzball}. The most well known examples from 1980s are
probably Noel Chiappa's C Gateway~\cite{cgw}, which was the basis for the MIT
startup Proteon~\cite{proteon}, and William Yeager's ``Ships in the Night''
multiple-protocol router~\cite{ships}, which was the basis for the Stanford
startup Cisco Systems.

This approach of building routers in software lasted up until the mid 90s, when
software could no longer keep up with the increase in link speeds that caused
by the rapid adoption of the Internet and the World Wide Web. Juniper Network's
M40 router~\cite{juniperm40} was an early example of a hardware router in 1998.
As we described in Chapter~\ref{chap:intro}, since the mid 90s, the fastest
routers have predominantly been architected out of dedicated hardware because
hardware specialization is the only way to sustain the yearly increases in link
speeds (Figure~\ref{fig:router_evolution}).

\section{Active Networks (mid 90s)}
The mid 90s saw the development of active networks~\cite{ants, switchware}, an
approach that advocated that the network be programmable or ``active'' to allow
the deployment of new services in the network infrastructure. There were at
least two approaches to active networks. First, the programmable router
approach~\cite{switchware}, which allowed a network operator to program a
router in a restricted manner. Second, the capsule approach~\cite{ants}, where
end hosts would embed whole programs into packets as capsules, which would then
be executed by the router.

Active networks came to be associated mostly with the capsule
approach~\cite{sdn_history}, which raised important security concerns. Because
programs were embedded into packets by end users, it raised the possibility
that a malicious or erroneous program could corrupt the entire router. These
concerns were resolved by executing the program within an application-level
virtual machine like the Java virtual machine~\cite{ants}, but this came at the
cost of degraded forwarding performance. As an example, the SNAP~\cite{snap}
system that prototyped the capsule approach had a forwarding rate of 100
Mbit/s, which was two orders of magnitude slower than the Catalyst 32 Gbit/s
hardware router at that time~\cite{catalyst}.
%TODO Check this.

%TODO: E2e argument and active networks
%Reed's critique and Wetherall's response

\section{Software routers (1999 to present)}
%In a sense, NFV is an embodiment of software routers.
%So is AT&T's domain 2.0
% Cite the EPC paper from SIGCOMM 2017?
% Cite netbricks
% So are all the WiFi access points
% Click (99), IXPs (2001), RouteBricks, PacketShader, NetFPGA, etc., and associated languages for software routers (packetC, Intel's C dialects, etc.).
% Turn a CPU/GPU/FPGA/multi-core into a router

%%Software routers~\cite{routebricks, click} and network processors~\cite{ixp4xx}
%%are flexible, but at least 10$\times$--100$\times$ slower than programmable
%%routers~\cite{xpliant, tofino}.  FPGA-based platforms like the Corsa DP
%%6440~\cite{corsa}, which supports an aggregate capacity of 640 Gbit/s, are
%%faster, but still 5$\times$--10$\times$ slower than programmable
%%routers~\cite{tofino, xpliant}.

% We borrow from the early languages for programming software routers
Many programming languages target
the network control plane~\cite{frenetic, maple}. \pktlanguage focuses on the
data plane. Several DSLs target the data plane. Click~\cite{click} uses C++ for
packet processing on software routers. packetC~\cite{packetc}, Intel's
auto-partitioning C compiler~\cite{intel_uiuc_pldi}, and Microengine
C~\cite{microenginec} target network processors. \pktlanguage's C-like syntax
and sequential semantics are inspired by these DSLs. However, because it
targets line-rate routers, \pktlanguage is more constrained. For instance,
because compiled programs run at line rate, \pktlanguage forbids loops, and
because \absmachine has no shared state, \pktlanguage has no synchronization
constructs.

\section{Software-defined networking (2003 to now)}
% RCP, 4D, FORCES
% SANE, Ethane, OpenFlow, and
% associated languages (Pyretic, Frenetic, etc.).
% Could incorporate OpenSketch, FAST, DevoFlow, etc. here
% Unified interface to high-speed switching chips
% Promise: this unified interface will solve all our programmability problems

\section{Edge-based software-defined networking (2013 to now)}
%https://www.sdxcentral.com/articles/news/scott-shenker-preaches-revised-sdn-sdnv2/2014/10/
% One possibility for SDNv2.0: Fabric-based SDN (HotSDN 2013), edge-core split
% Too much feature creep in OpenFlow; propose that routers just do source routing, edge does rest
% Middleboxes,

\section{Programmable switching chips (2013 to now)}
Recent academic work~\cite{rmt} and commercial router chips~\cite{tofino,
flexpipe, xpliant} have considered the problem of building routers that are
both fast and programmable. The P4 programming language~\cite{p4} has emerged
as an industry effort towards a standard programming language for these chips.
To the extent that we can glean from publicly available documents, these chips
provide flexibility on only two counts: recognizing user-specific header
formats and programmatically manipulating packet headers for functions such as
forwarding, tunneling, and access control. In particular, they do not provide
the programmability required to implement the grayed-out algorithms in
Figure~\ref{fig:router_evolution}.  These algorithms require the ability to
programmatically manipulate router state on every packet, the ability to
program which packet a router link must transmit next, and the ability to
program what statistics a router must measure. We hope this
dissertation suggests directions in which programmable router
 chips could evolve in the future.

% Lavanya's work
Jose et al.~\cite{lavanya_compiler} focus on compiling P4 programs to
programmable data planes such as the RMT and FlexPipe~\cite{flexpipe} architectures. Their work
focuses only on compiling stateless data-plane tasks such as forwarding and
routing, while the \pktlanguage compiler handles stateful data-plane
algorithms.

\section{Concurrent work on enabling network programmability (2013 to now)}
% FastPass/Flexplane: Centralized data plane
% TPP, INT (modest version of active networks)
% Eden
Eden~\cite{eden} provides a programmable data plane using commodity routers by
programming end hosts alone. \pktlanguage targets programmable routers that
provide more flexibility relative to an end-host-only solution. For instance,
\pktlanguage allows us to program in-network congestion control and AQM
schemes, which are beyond Eden's capabilities.  Tiny Packet Programs
(TPP)~\cite{tpp} allow end hosts to embed small programs in packet headers,
which are then executed by the router. TPPs use a restricted instruction set to
facilitate router execution; we show that router instructions must and can be
substantially richer (Table~\ref{tab:templates}).
% NetASM:

% Abstract machines for line-rate routers.
The closest work related to the \absmachine machine model is
NetASM~\cite{netasm}. NetASM is an abstract machine and intermediate
representation (IR) for programmable data planes that is portable across
network devices: FPGAs, virtual routers, and line-rate routers.  \absmachine
is a low-level machine model for line-rate routers alone and can be used as a
NetASM target. Because of its role as a low-level machine model, \absmachine
models practical constraints required for line-rate operation
(\S\ref{s:atomConstraints}) that an IR like NetASM does not have to. For
instance, \absmachine machines do not permit sharing state between atoms and use
atom templates to limit computations that can happen at the router's line rate.

% SNAP (network transactions)
% \Para{Stateful packet-processing abstractions.}
SNAP~\cite{snap} programs stateful data-plane algorithms using a network
transaction: an atomic block of code that treats the entire network as one
router~\cite{onebigswitch}. It then uses a compiler to translate network
transactions into rules on each router. SNAP needs a compiler to compile these
router-local rules to a router's pipeline, and can use \pktlanguage for this
purpose.

% FAST
FAST~\cite{fast} provides router support and software abstractions for
state machines. \absmachine's atoms support more general stateful processing
beyond state machines that enable a much wider class of data-plane algorithms.

% UPS (programmable scheduling from the edge)

\Para{Universal Packet Scheduling (UPS).} UPS~\cite{ups} shares our goal of
flexible packet scheduling by seeking a single scheduling algorithm that is
{\em universal} and can emulate any scheduling algorithm. Theoretically, UPS
finds that the well-known LSTF scheduling discipline~\cite{lstf} is universal
if packet departure times for the scheduling algorithm to be emulated are known
up front. Practically, UPS shows that by appropriately initializing slacks, many different scheduling objectives can be
emulated using LSTF. LSTF is programmable using PIFOs, but the set of schemes
practically expressible with LSTF is limited. For example, LSTF cannot
express:
\begin{CompactEnumerate}
\item Hierarchical scheduling algorithms such as HPFQ, because it
  uses only one priority queue.
\item Non-work-conserving algorithms. For such algorithms LSTF must know the
  departure time of each packet up-front, which is not practical.
\item Short-term bandwidth fairness in fair queueing, because LSTF maintains no
  router state except one priority queue. As shown in
  Figure~\ref{fig:sched_trans}, programming a fair queueing algorithm requires us
  to maintain a virtual time state variable. Without this, a new flow could have
  arbitrary virtual start times, and be deprived of its fair share indefinitely.
  UPS provides a fix to this that requires
  estimating fair shares periodically, which is hard to do in
  practice.
  %TODO: Check that this point is accurate.
\item Scheduling policies that aggregate flows from distinct endpoints into a
  single flow at the router. An example is fair queueing across video and web
  traffic classes, regardless of endpoint.  Such policies require the router to
  maintain the state required for fair queueing because no end point sees all the
  traffic within a class.  However, LSTF cannot maintain and update router state
  progammatically.
\end{CompactEnumerate}
\an{The restrictions in UPS/LSTF are a result of a limited programming
model. UPS assumes that routers are fixed and cannot be programmed to modify
packet fields. Further, it only has a single priority queue.  By using atom
pipelines to execute scheduling and shaping transactions, and by composing
multiple PIFOs together, PIFOs express a wider class of scheduling algorithms.}

%\begin{figure}
%  \centering
%  \includegraphics[width=0.7\columnwidth]{state_reqd.pdf}
%  \caption{A router's scheduling algorithm, such as WFQ, might aggregate flows
%  from different end hosts into a single flow at the router for the purpose of
%  scheduling.}
%  \label{fig:state}
%\end{figure}

% UnivMon (single mechanism for measurement of counters)
% SONATA etc (measurement using OpenFlow switches; similar programming model, but doesn't innovate on the hardware front)
% Difference relative to all this work is that we focus on both hardware and software, which
% allows us to get more systems leverage, demonstrating the power of joint design, relative 
% to SNAP, UnivMon, SONATA, Eden, and maybe even UPS (depending on how you interpret it)

%TODO
%%\Para{Packet scheduling algorithms.}
%%The literature is replete with scheduling algorithms~\cite{pFabric, hpfq,
%%stopngo, stfq, lstf, srpt, drr, rcsd} . Yet, line-rate routers support only a
%%few: DRR, traffic shaping, and strict priorities. As \S\ref{s:expressive}
%%shows, PIFOs allow a line-rate router to run many of these scheduling
%%algorithms, which, so far, have only been run on software routers.

\Para{Hardware designs for priority queues.}
\an{P-heap is a pipelined binary heap scaling to 4-billion entries~\cite{bhagwan,
pheap}.  However, each P-heap supports traffic belonging to a {\em single} 10
Gbit/s input port in an input-queued router; there is a separate P-heap
instance for each port~\cite{bhagwan}.  Having a separate P-heap per port incurs prohibitive
area overhead on a shared-memory router, and prevents sharing of the data
buffer and binary heap across output ports. Conversely, it is not easy to
overlay multiple logical PIFOs over a single P-heap, which would allow the
P-heap to be shared across ports.}
%%
%%\an{
%%In contrast to a hardware implementation of a generic priority queue as a heap,
%%our design for the PIFO exploits two domain-specific insights. First, there is
%%considerable structure in the ranks: ranks within a flow strictly increase with
%%time.  Second, the packet buffers on shared-memory routers used in datacenters
%%today are much smaller than those on deep-buffered core routers in the past.
%%This permits a simpler, albeit less scalable, design relative to heaps.
%%}

\Para{Endpoint-based monitoring.} Owing to limited router support for
measurement, many systems monitor network performance from endpoints
alone~\cite{netpoirot, minlan-snap, dapper-sosr, trumpet, azure-smartnic}.
While endpoint solutions are necessary for application context (\eg socket
calls), they are inadequate to debug all network problems. A real network needs
both endpoint and router-based systems because each sees something the other
cannot.

\Para{Router-based monitoring.} Traditionally, router-based monitoring has
focused on per-flow counts, not performance measurement. For example,
NetFlow~\cite{netflow} and sFlow~\cite{sflow} provide traffic summaries
through flow and packet sampling. Packet-capture systems~\cite{cisco-span,
niksun, netsight, everflow, pathdump, path_query} collect entire packets or
digests. These approaches sample extensively to lower collection
overheads, and are useful for posthoc traffic analysis. However, neither
approach captures details of {\em performance} phenomena (\eg TCP incast) as
specified by a flexible language like \TheSystem.

\Para{Sketches.} Sketches~\cite{univmon, flowradar, counterbraids, dream} and
earlier work on programmable router measurements~\cite{progme, opensketch}
provide traffic volume statistics using summary data structures on routers.
Unlike sketches, \TheSystem does not have an accuracy-memory tradeoff, since
counting is linear-in-state and counters can be scalably implemented in \TheSystem. Instead,
\TheSystem trades off memory size with cache eviction rate (\Sec{eval}).
\TheSystem also allows users to perform a broader set of aggregations with full
accuracy.

%% \TheSystem also enables users
%% to perform other more general aggregations without losing accuracy.

%
%With INT alone, performance information may be lost, since packets carrying the
%INT data may be dropped on the way to endpoints.

\Para{Recent router support for measurement.}
In-band Network Telemetry (INT)~\cite{int, tpp} exposes queue lengths to
endpoints by stamping it on the packet itself. \TheSystem builds on INT and
provides flexible filters and aggregations {\em directly in routers}.
\TheSystem's data aggregation in routers saves the bandwidth needed to collect
INT data distributed over many endpoints.  In addition, the Tetration chip
provides flow-level telemetry, exposing a fixed set of metrics including
latency, window and packet size variation, and a ``burst
measurement''~\cite{tetration-telemetry}. In contrast, \TheSystem provides
programmable aggregation functions and flow definitions, \eg input/output port versus 5-tuple.

\Para{Network query languages.} Prior network query languages~\cite{gigascope,
frenetic, path_query, streaming-monitoring} allow users to ask questions
primarily about traffic volumes, since their input data is
collected using NetFlow and match-action rule counters~\cite{openflow}. In
contrast, \TheSystem enables expressive {\em performance} questions on
data collected with purpose-built router hardware. \TheSystem shares some
language constructs with Gigascope~\cite{gigascope} and
Sonata~\cite{streaming-monitoring}, but supports aggregations directly in the
router.
%functional and relational constructs

\Para{Language-directed computer design.} Language-directed hardware design (Chapter~\ref{chap:perf_query})
is inspired by language-directed computer design~\cite{language-directed-computer-design,
ditzel_patterson, soar}, aimed at designing efficient hardware to support
expressive high-level languages.

% Other related work, which needs to be mentioned somewhere

%%%9. http://www.srl.inf.ethz.ch/papers/sosp15-symple.pdf is very related work to our linear-in-state characterization:
%%%
%%%This system (called Symple) shares many of the same goals as Marple's aggregation
%%%implementation: http://www.srl.inf.ethz.ch/papers/sosp15-symple.pdf
%%%The introduction should be sufficient to understand the problem they
%%%are tackling.
%%%
%%%Figure 1 captures an example of an aggregation that they can
%%%parallelize (we should see if Figure 1 is linear-in-state), while
%%%Figure 2 captures the essence of their approach. Some of their
%%%restrictions in section 4.3 seem similar to ours. For instance,
%%%1. They encodes integers as affine transformations of other integers.
%%%2. They only allows multiplication of integers only with constants, and
%%%3. They don't permit division operations on integers.
%%%
%%%It might be worthwhile understanding more deeply what the differences
%%%and similarities between Marple and Symple are.
%%%
